FORMAT: 1A
HOST: https://partnersdev.capio.ai/api/v1/

# Capio

This page will help you get started with Capio. You'll be up and running in a jiffy!

Welcome to the Capio API! This API lets use access some of Capio's components - automated speech recognition and natural language understanding.

## API Key
In order to consume the API, you will need an API key. You may request an API from your point of contact at Capio.

## Notes
This API is still under development, but we're working hard to improve it! If you notice the docs are out of date or are unclear, please don't be shy about clicking the "Suggest Edits" link! We're working to keep these docs up to date, however sometimes we get behind – and we'd love your help.

## Speech Recognition Flowchart
Below is a flowchart describing the connection process from a client to Capio’s embedded ASR server.
Once connection to ASR-Server is established, the client the client need to send a context message (Context Message) with parameters detailed [later](#context). 
After the context is sent, the client sends a stream of audio packets (Audio Message) to the ASR-Server, 
and asynchronously receives speech recognition results (Result Message). 
This will provide customized ASR service based on speech context and user preferences.

![Flowchart](https://www.filepicker.io/api/file/KWZwj7KATsuwZDF981MX)
ASR server flowchart (dotted block is optional)


## Transcription [/speech/transcribe]
Using Capio's API, you may upload your audio file and request transcription. 
Capio offers a REST API and Websocket API. 
Once you get used to the flow and concept by REST API, we recommend to use Websocket API for less transaction overheads.

### REST API [POST] 
REST API takes a request with audio file and context. 

#### cURL API call example
Once you launch your service and have the API key, try the following sample cURL call:

    curl -X POST -F "audio=@<audio_file>" -F "context={\"apiKey\":\"<api_key>\"}" "https://partnersdev.capio.ai/api/v1/speech/transcribe"

#### <a name="context" />Context Parameters
As you see in the above cURL call, a trascription request requires a JSON object called "context".
Context need to include your API key and language selection, and can also contain your preferences for transcription.
The following table shows the fields for a context.

| Fields    | Description   | Example   | Required? (default)
| ------------- |-------------|--------- | ---------
| apiKey    | API key generated for your service   | 1234567890asdfghjkl   | **Yes**
| partial    | Enable partial results | true / false   | No (false)
| autostop    | Enable server side to detect the end of utterance | true / false   | No (false)
| timestamp   | Add word level timestamp to result message | true / false | No (false)
| word_confidence | Add word level confidence to result message | true / false | No (false)


#### <a name="result" />Result message
When your request is processed correctly, a Result Message is sent in the format of a JSON "result" object. 
Partial results are returned from the ASRserver asynchronously while the audio packets are being received. 
The final result ("final": true) is returned once the user has completed speaking. 
The result message is structured as follows:

* result : main ASR result JSON array object
    * alternative:  n-best results in an array
        * confidence: sentence level confidence score (float)
        * transcript: recognized word sentence (string)
        * (optional) timestamp: word level timestamp in an array of {word, start_time, end_time}
        * (optional) word_confidence: word level confidence in array of {word, confidence}
        * stability: sentence stability provided for a partial result indicating how likely the result is to change (flow)
    * final: end of sentence recognition (boolean - true for final results and false for partial results)
* result_index: index of this sentence since start of transaction (int)

##### Example partial response
```JSON
{
    "result":[
        {
        "alternative":[
            {
            "transcript":"<silence> I am"
            }
        ],
        "final":false,
        "stability":1
        }
    ],
    "result_index":0
}
```

##### Example final response
```JSON
{
    "result":[
        {
        "alternative":[
            {
                "confidence":1,
                "timestamp":[
                    [
                        "<silence>",
                        0,
                        0.27190783619880676
                    ],
                    [
                        "I",
                        0.27190783619880676,
                        0.42173266410827637
                        ],
                    [
                        "am",
                        0.42173266410827637,
                        0.57999998331069946
                    ],
                    :
                    :
                    [
                        "<silence>",
                        2.3499999046325684,
                        2.559999942779541
                    ]
                ]
                "transcript":"<silence> I am going to be busy <silence> this weekend <silence>",
                "word_confidence":[
                    [
                        "<silence>",
                        1
                    ],
                    [
                        "I",
                        0.93640512228012085
                    ],
                    [
                        "am",
                        0.93640512228012085
                    ]
                    :
                    :
                    [
                        "<silence>",
                        1
                    ]
                ]
            }
        ],
        "final":true
        }
    ],
    "result_index": 0,
    "transactionID": "abcdefghijklmnopqrstuvwxyz12345"
}
```
#### Error messages
Error messages are sent when your request is not processed. The following table shows the error messages and their reasons.

| Code    | Message   | How to fix
| ------------- |-------------|--------- 
| 400    | Please use [audio] for the audio file field name in your POST request.   | Include '-F "audio=@<audio_file>"'
| 400    | API Key not provided. Please use the [apiKey] or [context] parameter in your POST request. | Include '-F "context={\"apiKey\":\"<apiKey>\"}"'
| 500    | Error processing media file. | Upload audio file

+ Request (multipart/form-data; boundary=---BOUNDARY)

    -----BOUNDARY
    Content-Disposition: form-data; name="audio"; filename="test.wav"
    Content-Type: application/octet-stream
    
    -----BOUNDARY
    Content-Disposition: form-data; name="context"
    Content-Type: application/json
    
    context={"apiKey":"<api_key>"}
    -----BOUNDARY

+ Response 201 (application/json)
    + Body
        {
            "result":[
                {
                    "stability":0.9,    //optional: only for partial hypothesis
                    "alternative":[
                        {
                        "confidence":0.6563087704653612,
                        "transcript":"show me the weather forecast for chicago usa and two days from now"
                        }, {
                        "confidence":0.2848067295368003,
                        "transcript":"show me the weather forecast for chicago usa in two days from now"
                        }, {
                        "confidence":0.05888449999783865,
                        "transcript":"show me the weather forecast for chicago usa two days from now"
                        }
                    ],
                    "final":true
                }
            ]
        }
            
+ Response 400 (application/json)
    + Body
        {
            "code":400,
            "message":"Please use [audio] for the audio file field name in your POST request."
        }
        
+ Response 500 (application/json)
    + Body
        {
            "code":500,
            "message":"Error processing media file."
        }

### Websocket API [POST]
Capio's realtime streaming API is exposed over WebSockets via socket.io. 
Websocket API expects the same flow of transactions and the same structure of [context](#context) and [result](#result) messages as the REST API. 

#### Reference client
You can see and download the reference client and implementation in NodeJS at [our Git repository](http://git.capio.ai/capio/tools-generic-internal/tree/public-node-client/node-asr-client).

#### Pseudocodes
The pseudocode below demonstrates the consumption of the API in C#, Java and NodeJS:

##### Node.JS: Complete client code is [here](http://git.capio.ai/capio/tools-generic-internal/blob/public-node-client/node-asr-client/app.js)

```Javascript
var requestContext = {
    'apiKey': '<api_key>',
    'clientType': 'NodeJS',
    'partial': false,
    'autostop': false,
    'nbest': 1
};

var socket = io.connect('ws://partners.capio.ai', {transports: ['websocket']});

socket.on('connect_error', function (data) {
  console.log('Unable to connect to WebSocket endpoint');
  console.log("ERROR: ", data);
  process.exit(-1);
});

socket.on('connect', function () {
  socket.send({ context: JSON.stringify(requestContext) }, function () {
    var data = fs.readFileSync(program.args[0]);

    for (var i = 0; i < data.length; i += packetSize) {
      chunk = data.slice(i, i + packetSize);
      socket.send({ audio: chunk });
    }
    socket.send({ disconnect: true })
  });
});

socket.on('message', function (data) {
    console.log(data);
});

socket.on('disconnect', function () {
  process.exit(0);
});
```

##### Java

```Java
String audioPath = args.length == 1 ? args[0] : "audio.wav";

final Semaphore semaphore = new Semaphore(0);

final JSONObject audio = new JSONObject();

audio.put("audio", readFile(audioPath)); // Read the audio file as a array

final JSONObject disconnect = new JSONObject();
disconnect.put("disconnect", true);

IO.Options options = new IO.Options();
options.forceNew = true;
options.reconnection = false;
options.transports = new String[] {
  "websocket"
};

final Socket socket = IO.socket("http://partners.capio.ai", options);

socket.on(Socket.EVENT_CONNECT, new Emitter.Listener() {

  public void call(Object...args) {
    
    // Send the context JSONObject
    socket.send(context);
    
    // If the audio file is larger than 10000 bytes, loop through it and send it in smaller chunks.
    socket.send(audio);
  }
});

socket.on(Socket.EVENT_MESSAGE, new Emitter.Listener() {

  public void call(Object...args) {

    System.out.println(args[0]);

    semaphore.release();
  }
});

socket.on(Socket.EVENT_DISCONNECT, new Emitter.Listener() {

  public void call(Object...args) {

  }
});

socket.on(Socket.EVENT_ERROR, new Emitter.Listener() {

  public void call(Object...args) {

  }
});

socket.connect();

semaphore.acquire();

socket.send(disconnect);
```

##### C\# 
```cs
ManualResetEvent resetEvent = new ManualResetEvent(false);

string audioFilePath = "//path/to/audio.wav"; //Should be a 16KHz uncompressed wav file

byte[] audioFile = File.ReadAllBytes(audioFilePath);

var ctx = new JObject
{
    {"sys", "GPU"},
    {"userID", "test@dev.capio.ai"},
    {"scriptID", 0},
    {"apiKey", "<api_key>"},
    {"language", "en-US"},
    {"prompt", "partial"},
    {"partial", false},
    {"autostop", false},
    {"nlu", false},
    {"nbest", 1},
    {"pronunciation", 0}
}.ToString();

var context = new JObject
{
    {"context", ctx}
};

var disconnect = new JObject
{
    {"disconnect", true}
};

var options = new IO.Options { Transports = ImmutableList.Create("websocket") };

var socket = IO.Socket("wss://partners.capio.ai", options);

socket.On(Socket.EVENT_CONNECT, () =>
{
    Console.WriteLine("C O N N E C T");

    Console.WriteLine("Sending context");
    socket.Send(context);

    Thread.Sleep(1000);

    Console.WriteLine("Sending audio");

    // Each audio chunk should not exceed 100000 bytes
    for (int i = 0; i <= audioFile.Length; i += 100000)
    {
        var arr = audioFile.Skip(i).Take(100000).ToArray();

        var audio = new JObject
        {
            {"audio", arr }
        };

        socket.Send(audio);
    }

    Thread.Sleep(1000);

    Console.WriteLine("Sending disconnect");
    socket.Send(disconnect);
});

socket.On(Socket.EVENT_MESSAGE, data =>
{
    Console.WriteLine(data.ToString());
});

socket.On(Socket.EVENT_CONNECT_ERROR, (err) =>
{
    Console.WriteLine("E R R O R");

    Console.WriteLine(err.ToString());
});

socket.On(Socket.EVENT_CONNECT_TIMEOUT, (err) =>
{
    Console.WriteLine("T I M E O U T");

    Console.WriteLine(err.ToString());
});

socket.On(Socket.EVENT_DISCONNECT, (err) =>
{
    Console.WriteLine("D I S C O N N E C T");

    resetEvent.Set();
});

resetEvent.WaitOne();